
---
## Summery

### 1. 带部分主元的高斯消元法 (Gaussian Elimination with Partial Pivoting - GEPP)回顾
* **部分主元法**：在第 `i` 列中，从第 `i` 行到第 `n` 行找到绝对值最大的元素 `A(k,i)`，并将其所在行 `k` 与当前行 `i` 交换。
* **目的**：这样做可以保证用作除数的 `A(i,i)` 是该列（剩余部分）中最大的，从而使得计算得到的商（乘数因子）的绝对值小于等于1，这有助于算法的数值稳定性。
* **LU分解**：该算法计算的是 `A = P*L*U`，其中 P 是一个置换矩阵。
* **基本GE算法的问题**：
    * `A(i+1:n,i) = A(i+1:n,i) / A(i,i)` 是 **BLAS1** 操作（向量缩放）。
    * `A(i+1:n,i+1:n) = A(i+1:n,i+1:n) - A(i+1:n,i) * A(i,i+1:n)` 是 **BLAS2** 操作（秩-1更新）。
    * BLAS3（矩阵乘法）通常比BLAS1和BLAS2快得多。

---
### 2. 将BLAS2转换为BLAS3：分块与延迟更新
* **分块 (Blocking)**：与优化矩阵乘法类似，但因GEPP中的数据依赖性而更复杂。
* **核心思想：延迟更新 (Delayed Updates)**：
    * 将连续若干个（例如 `b` 个）BLAS2（秩-1）更新操作累积起来。
    * 然后一次性地将这些累积的更新作为一个BLAS3（矩阵乘法）操作应用于“拖尾矩阵” (trailing matrix)。
* **块大小 `b` 的选择**：
    * `b` 应足够小，以使包含 `b` 列的活动子矩阵能装入缓存。
    * `b` 应足够大，以使BLAS3（矩阵乘法）操作高效。
* **分块高斯消元步骤** (处理 `b` 列为一个块) ：
    1.  对当前 `b` 列组成的面板 `A(ib:n, ib:end)` 应用BLAS2版本的GEPP，得到 `P'*L'*U'` 。
    2.  更新U的右侧部分：`A(ib:end, end+1:n) = LL⁻¹ * A(ib:end, end+1:n)`，其中 `LL` 是 `A(ib:end, ib:end)` 的严格下三角部分加单位阵。
    3.  应用延迟更新（BLAS3操作）：`A(end+1:n, end+1:n) = A(end+1:n, end+1:n) - A(end+1:n, ib:end) * A(ib:end, end+1:n)`。

---
### 3. 分布式内存机器上的任务/数据划分与分配
* **共享内存机器**：全局数据不专属于任何线程，任务分配灵活性大。
* **分布式内存机器**：数据必须分布到各个进程，任务分配灵活性降低。数据交换通过消息传递完成，必须考虑最小化通信成本。
* **并行GE的数据布局方式** ：
    * **1D列块状布局**：负载均衡差，P0在处理完前n/4步后空闲。
    * **1D列循环布局**：负载均衡好，但不容易使用BLAS3。
    * **1D列块循环布局**：可以通过选择块大小 `b` 来权衡负载均衡和BLAS3性能，但块的分解可能是瓶颈。
    * **块倾斜布局 (Block Skewed Layout)**：寻址复杂，每列中，行和列都是瓶颈。
    * **2D行列块状布局**：负载均衡差，P0在处理完前n/2步后空闲。
    * **2D行列块循环布局**：通常是较优选择 ("The winner!")。
* **分布式内存LU分解算法步骤概览** ：
    1.  分块处理，每次处理 `b` 列。
    2.  对当前块列：
        * 寻找主元行 `k`，进行列广播 (column broadcast)。
        * 在块列内交换行 `k` 和 `i`，广播行 `k` 。
        * 计算乘数因子 `A(i+1:n,i) = A(i+1:n,i) / A(i,i)` 。
        * 更新当前块列内的拖尾子矩阵 `A(i+1:n,i+1:end) -= A(i+1:n,i) * A(i,i+1:end)`。
    3.  将所有行交换信息向左右广播 。
    4.  将行交换应用于其他列 。
    5.  将计算得到的 `LL`（L的当前块部分）向右广播 。
    6.  更新U的右侧部分 `A(ib:end, end+1:n) = LL \ A(ib:end, end+1:n)`。
    7.  将更新后的 `A(ib:end, end+1:n)` 向下广播。
    8.  将更新拖尾矩阵所需的 `A(end+1:n, ib:end)` 向右广播。
    9.  更新拖尾矩阵 `A(end+1:n, end+1:n)`。

---
### 4. MPI 派生数据类型 (Derived Datatypes)
* **目的**：MPI允许用户基于其预定义的基本数据类型（如`MPI_CHAR`, `MPI_INT`等）构建自定义数据类型。
* **优点**：
    * 能够通过单次MPI调用通信非连续数据或不同数据类型的数据。
    * 使代码更紧凑和易于维护。
    * 使非连续数据通信更高效（取决于实现）。
* **应用场景**：可用于点对点通信和集体通信 。
* **问题**：如何高效发送/接收非连续数据（如矩阵的一列）？
    * 逐个元素发送：多次小消息，启动开销大。
    * 打包到临时缓冲区再发送：额外的内存拷贝开销。
    * **目标**：使用单条消息发送/接收非连续数据，且无需额外拷贝。即，非连续数据直接拷贝到网络通信缓冲区，或从网络缓冲区直接拷贝到用户内存的非连续位置。
* **定义新数据类型的步骤** ：
    1.  声明一个 `MPI_Datatype` 类型的变量（如 `MPI_Datatype new_type;`）。
    2.  使用MPI提供的构造函数构建数据类型（如 `MPI_Type_vector(...)`）。
    3.  提交数据类型（`MPI_Type_commit(&new_type);`）。
    4.  使用新数据类型进行通信。
    5.  不再需要时释放数据类型（`MPI_Type_free(&new_type);`）。
* **常用的MPI派生数据类型构造函数**：
    * **`MPI_Type_contiguous(count, oldtype, &newtype)`** ：创建一个由 `count` 个连续的 `oldtype` 元素组成的新类型。
        * 示例：发送矩阵 `a` 的第1行的前 `n` 个元素。
    * **`MPI_Type_vector(count, blocklen, stride, oldtype, &newtype)`**：创建一个由 `count` 个块组成的新类型，每个块包含 `blocklen` 个 `oldtype` 元素，块与块之间的起始位置间隔 `stride` 个元素 。
        * 非常适合表示矩阵的一列或等间隔的非连续数据 。
        * 示例图示：`count=3` 个块，每个块 `blocklen=2` 个 `oldtype` 元素，块间距 `stride=3`。
        * 应用：发送矩阵 `a` 的第2行（使用 `row_t`，通过 `MPI_Type_contiguous` 创建）和第1列（使用 `col_t`，通过 `MPI_Type_vector` 创建）。
        * 接收列数据到连续缓冲区或直接到矩阵的非连续列位置。
    * **`MPI_Type_indexed(count, blocklens[], displs[], oldtype, &newtype)`** ：创建由 `count` 个块组成的新类型，每个块可以有不同的块长度 (`blocklens[]`) 和相对于起始点的位移 (`displs[]`)。
        * 示例：发送上三角矩阵。
    * **`MPI_Type_create_subarray(...)`**：用于发送矩阵的子矩阵。
    * **`MPI_Type_struct(...)`** ：比 `indexed` 更通用，可以包含多种不同的数据类型。

---
### 5. MPI 笛卡尔拓扑 (Cartesian Topology Routines)
* MPI允许程序员将处理器组织成逻辑上的k维网格。
* 进程ID可以映射到对应高维网格的新通信域 。
* 映射的好坏取决于程序的交互模式和机器的拓扑结构。
* **主要函数**：
    * `MPI_Cart_create(...)`：创建笛卡尔拓扑。
    * `MPI_Cart_coord(...)`：根据进程在组内的rank确定其在笛卡尔拓扑中的坐标。
    * `MPI_Cart_rank(...)`：根据进程在笛卡尔拓扑中的坐标确定其rank。
    * `MPI_Cart_shift(...)`：根据给定的位移方向和量，找到源和目标进程的rank。
    * `MPI_Cart_sub(...)`：将笛卡尔拓扑划分为子网格。

---
### 6. 讲义总结要点
* **分布式内存特性** ：
    * 每个进程有独立的本地地址空间。
    * 局部变量不能被其他进程访问（无共享变量）。
    * 无所有进程均可访问的全局变量。
    * 数据交换必须通过显式的消息传递（send/receive变体）。
* **分布式内存编程考虑** ：
    * 需同时考虑数据和任务的划分与分配。
    * 数据/任务分配的限制性更强。
    * 必须认真考虑数据局部性、负载均衡和资源利用效率。
    * 存在额外的数据通信成本，必须考虑如何最小化通信开销。
* **MPI (Message Passing Interface)** ：
    * 用于开发可移植消息传递程序的行业标准库。
    * 几乎所有商业并行计算机都有供应商实现的MPI。
    * SPMD (Single Program Multiple Data) 编程模式：所有进程运行相同程序，但处理不同数据或程序的不同部分。使用rank (0 到 P-1) 来区分不同进程的行为。
* **已学习的MPI例程回顾** 。

---
## lecture10 中的问题与解答

**Lab Exercise 1**
* **任务**：修改之前的行块循环划分程序，实现列块循环划分，并将划分后的列块分发、修改、再收集回0号进程。
* **解**：
    * 正确实现列块循环的数据索引和分发逻辑。
    * 使用MPI派生数据类型（如 `MPI_Type_vector`）来高效地发送和接收非连续的列块数据，避免手动打包/解包。

**Lab Exercise 2**
* **任务**：模拟并行块高斯消元中，一个进程轮流向其他进程广播列块乘数因子以更新拖尾子矩阵的过程。
* **解**：
    * 实现进程间的轮流广播机制。
    * 正确处理每次广播后块大小（行数）减少的逻辑。
    * 使用 `MPI_Bcast` 进行广播。
    * 数据在接收方工作数组 `AW` 中的正确覆盖。

**Lab Exercise 3**
* **任务**：模拟并行块高斯消元中，一个进程轮流广播一个小的 `b x b` 子矩阵的下三角部分的乘数因子，以更新首部行块。
* **解**：
    * 从列块 `AK` 中正确提取 `b x b` 子矩阵的下三角元素。
    * 使用MPI派生数据类型（可能需要 `MPI_Type_indexed` 或 `MPI_Type_struct` 如果元素非连续且形状复杂）来定义和广播这个下三角部分。
    * 处理每次广播后下一个列块行长减少 `b` 的逻辑。
