1. 同步 (Synchronization)
在共享内存编程中，同步至关重要，它主要用于两个目的 ：

保护共享数据：防止多线程同时读写造成的数据混乱，即“竞争条件” 。
强制执行顺序：确保代码块之间有正确的执行先后顺序 。
OpenMP 同步构造
#pragma omp critical

创建一个“临界区”，确保同一时间只有一个线程能执行该区域内的代码 。
这是一种互斥（mutual exclusion）机制，常用于保护需要多个步骤才能完成的更新操作，例如对一个共享计数器的 count++ 操作 。
#pragma omp atomic

同样提供互斥，但它更轻量，只适用于单条赋值语句，即对单个内存位置的更新 。
例如，将一个线程的局部计算结果 lsum累加到全局变量 sum 上（sum += lsum），使用 atomic 比 critical 更高效 。
#pragma omp barrier

设置一个“屏障”，所有线程必须到达这个点后，才能继续执行后面的代码 。
它强制进行全局同步。在 OpenMP 中，许多并行构造（如 parallel for）的末尾都有一个隐式屏障 。如果不需要这个隐式屏障，可以使用 nowait 子句来移除它 。

2. 数据依赖 (Data Dependency)  
指令级数据依赖 
流依赖 (RAW - Read After Write)：先写后读，这是真依赖，无法消除 。
反依赖 (WAR - Write After Read)：先读后写，非真依赖，可通过重命名变量等方式消除 。
输出依赖 (WAW - Write After Write)：先写后写，非真依赖，也可消除 。
循环携带数据依赖 (Loop-Carried Data Dependency)
这是并行化循环时必须检查的关键问题，指当前循环的计算依赖于之前循环的计算结果 。  
识别：如果循环中使用了非当前循环索引的数组元素（如 a[i+1]），或者一个变量的值在不同迭代中会发生改变 ，就需要警惕是否存在循环携带依赖。
处理方法：  
重构表达式：将依赖关系从循环中移除，例如将依赖变量的计算公式直接代入。  
循环拆分 (Loop Splitting)：如果一个循环内有多个语句，且它们之间存在依赖，可以尝试将它们拆分成两个独立的循环。利用两个循环之间的隐式屏障来保证正确的执行顺序。
3. 归约运算 (Reduction Operation)
归约是将一组数据通过一个满足结合律的操作（如 +, *, max, min 等）合并成一个单一值的过程。  
挑战：直接的顺序求和代码 S = S + a[i] 存在循环携带依赖，无法直接并行化 。
并行思路：利用加法的结合律，让每个线程计算一个“部分和”，最后再将所有部分和相加得到总和。  
reduction(op:list) 子句  
OpenMP 提供了 reduction 子句来自动处理这个过程。  
当使用 reduction(+:S) 时，OpenMP 会为每个线程创建一个私有的局部变量 S（并根据操作符初始化，如 + 对应 0，* 对应 1）。  
所有线程在自己的局部副本上进行计算，循环结束后，OpenMP 会自动将所有局部副本的值归约到原始的全局变量 S 上。  
4. 扫描运算 (Scan / Prefix Operation)
扫描运算（或称前缀和）是为数组 A 生成一个新数组 C，其中 C[i] 是 A 中前 i 个元素的累积运算结果。  
挑战：其顺序实现 c[i] = c[i-1] + a[i] 是典型的“真”数据依赖，无法直接并行。   
并行算法 (三阶段法) ：   
局部扫描：将原数组分块，每个线程对自己负责的块进行独立的扫描（前缀和）计算 。
块间归约扫描：由单个线程对第一阶段中每个块的“局部总和”进行一次扫描操作，得到每个块的偏移量。  
结果更新：每个线程用第二阶段计算出的偏移量，更新自己块内所有元素的扫描结果 。
性能：该并行算法虽然增加了总计算量（约 2n-1 次操作，而顺序算法为 n-1 次），但并行执行时间约为 2n/t + t，在线程数 t > 2 时通常会比顺序执行更快。    

5. 问题 1 :以下 for 循环可以并行化吗？  
答案：不可以。原因: 这个循环存在循环携带的流依赖 (RAW)。  
在第 i 次迭代中，d[i] 的计算需要读取 a[i] 的值 。  
而在上一次迭代（即第 i-1 次）中，a[i] 的值（即 a[(i-1)+1]）刚刚被写入 。
如果并行执行，可能会出现一个线程（例如 i=1）在另一个线程（i=0）完成对 a[1] 的写入之前，就去读取 a[1] 的旧值，从而导致 d[1] 的计算结果错误。因此，这个循环不能直接安全地并行化。
```C++
for (i=0; i<n; i++) {
    a[i+1] = b[i] + e[i];
    d[i] = e * a[i];
}
```

6. 问题 2 (Page 22): 实验练习：编写一个 OpenMP 程序来计算 n 个数字的总和。  
编写两个程序：一个使用 OpenMP reduction 子句，另一个让每个线程计算部分和然后手动累加，并比较它们的性能。  
reduction 版本: 直接在 #pragma omp parallel for 后加上 reduction(+:sum) 即可，这是最简洁高效的方式。
手动累加版本:  
在并行区域内，声明一个局部变量 lsum 用于计算部分和。  
使用 #pragma omp for 循环计算部分和 lsum。  
循环结束后，使用 #pragma omp critical 或 #pragma omp atomic 创建一个临界区，将每个线程的 lsum 安全地加到全局变量 sum 上。  
性能比较: 通常情况下，使用内置 reduction 子句的性能会优于或等于手动累加版本。因为编译器可以对 reduction 进行高度优化，而手动实现的 critical 或 atomic 可能会引入额外的同步开销。